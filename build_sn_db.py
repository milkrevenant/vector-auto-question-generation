import os, glob, json, chromadb, tiktoken
import hashlib, re
import numpy as np
from scipy.spatial.distance import cosine
from kiwipiepy import Kiwi
import time
from openai import RateLimitError, APIError, APIConnectionError, Timeout
 # â”€â”€ ê·¸ë£¹ í•´ì‹œ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def canonical_passage(item: dict) -> str:
    """passage ë˜ëŠ” context_boxë¥¼ ê³µë°± 1ì¹¸ìœ¼ë¡œ ì •ê·œí™”í•´ ë°˜í™˜"""
    txt = (item.get("passage") or item.get("context_box") or "")
    return " ".join(txt.split())

def passage_hash(item: dict, length: int = 12) -> str:
    """
    ë™ì¼ ì§€ë¬¸ì´ë©´ íŒŒì¼ëª…ì´ ë‹¬ë¼ë„ ë™ì¼ í•´ì‹œë¥¼ ì–»ë„ë¡ SHAâ€‘1 ê¸°ë°˜ ê·¸ë£¹í‚¤ ìƒì„±.
    ê¸°ë³¸ 12ì(48bit) â†’ ì¶©ëŒ í™•ë¥  1/2^48 â‰ˆ 1.4eâ€‘14
    """
    text = canonical_passage(item)
    return hashlib.sha1(text.encode("utf-8")).hexdigest()[:length]
 # â”€â”€ ìœ ì‚¬ë„ ê³„ì‚°ìš© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
kiwi = Kiwi()                 # Pureâ€‘Python í˜•íƒœì†Œ ë¶„ì„ê¸° (Java ë¶ˆí•„ìš”)

def pos_set(text: str):
    "í…ìŠ¤íŠ¸ë¥¼ í˜•íƒœì†Œ í’ˆì‚¬ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•´ ì§‘í•©ìœ¼ë¡œ ë°˜í™˜"
    return {tok.tag for tok in kiwi.tokenize(text)}

def pos_jaccard(a_set: set, b_set: set) -> float:
    "í’ˆì‚¬ ì§‘í•© Jaccard ìœ ì‚¬ë„ (0~1)"
    if not a_set or not b_set:
        return 0.0
    return len(a_set & b_set) / len(a_set | b_set)

def cosine_sim(v1: list, v2: list) -> float:
    "ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (âˆ’1~1) â†’ 0~1 ì •ê·œí™”"
    return 1 - cosine(v1, v2)   # scipy ë°˜í™˜ì€ distance
from openai import OpenAI

# â”€â”€ â¶ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SRC_DIR = "/Users/stillclie_mac/Documents/ug/snoriginal/db"
DB_PATH = "./sn_csat.db"               # DuckDB íŒŒì¼
COL_NAME = "sn_csat_openai"

# â”€â”€ â· ëª¨ë¸ & ë„êµ¬ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ (í™˜ê²½ë³€ìˆ˜ë¡œ ë®ì–´ì“°ê¸° ê°€ëŠ¥)
EMBED_MODEL = os.environ.get("OPENAI_EMBED_MODEL", "text-embedding-3-large")
print(f"ğŸ”§  Using embedding model: {EMBED_MODEL}")

openai  = OpenAI(timeout=60)   # 60â€‘sec clientâ€‘side timeout
client  = chromadb.PersistentClient(path=DB_PATH)
col     = client.get_or_create_collection(
             COL_NAME, metadata={"hnsw:space":"cosine"}
         )

def merge_text(item: dict) -> str:
    """
    ì§€ë¬¸ + ë¬¸ì œ + ì„ íƒì§€ë¥¼ í•œ ë¬¸ìì—´ë¡œ
    None ì´ë‚˜ ëˆ„ë½ í•„ë“œëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬í•´ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•œë‹¤.
    """
    passage  = item.get("passage") or item.get("context_box") or ""
    question = item.get("question") or ""
    choices  = " ".join(opt.get("text", "") for opt in item.get("options", []))
    return f"{passage}\n{question}\n{choices}"

# â”€â”€ â¸ ëª¨ë“  JSON íŒŒì¼ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
files = sorted(glob.glob(os.path.join(SRC_DIR, "*.json")))
print(f"ğŸ”  Found {len(files)} JSON files.")

pos_sets = []      # passageë³„ í’ˆì‚¬ ì§‘í•© ë³´ê´€
ids, docs, metas = [], [], []
for path in files:
    with open(path, encoding="utf-8") as f:
        item = json.load(f)
    # ì§ˆë¬¸(question)ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
    if not item.get("question"):
        print(f"âš ï¸  Skip {path} (missing question)")
        continue

    ids.append(item["id"])
    docs.append(merge_text(item))
    # í’ˆì‚¬ ì§‘í•© ì €ì¥ (ì§€ë¬¸/contextë§Œ ì‚¬ìš©)
    passage_text = item.get("passage") or item.get("context_box") or ""
    pos_sets.append(pos_set(passage_text))
    # ë©”íƒ€ë°ì´í„°ì—ì„œ None, dict, list íƒ€ì… ê°’ì„ ì œê±°(ChromaëŠ” dict/list í—ˆìš©í•˜ì§€ ì•ŠìŒ)
    clean_meta = {}
    for k, v in item.items():
        if k in ("passage", "question", "options"):
            continue
        if v is None:
            continue
        # primitive íƒ€ì…ë§Œ í—ˆìš©
        if isinstance(v, (str, int, float, bool)):
            clean_meta[k] = v
    # â€• ê·¸ë£¹ í•´ì‹œ ì¶”ê°€ â€•
    clean_meta["group"] = passage_hash(item)
    # ì›ë³¸ JSON íŒŒì¼ ê²½ë¡œ ì €ì¥
    clean_meta["file_path"] = path
    metas.append(clean_meta)

def embed(batch, max_retry=5, backoff=2):
    """
    Call OpenAI embedding with exponential backâ€‘off.
    Returns list[vector]. Raises last error after retries.
    """
    for attempt in range(1, max_retry + 1):
        try:
            res = openai.embeddings.create(model=EMBED_MODEL, input=batch)
            return [d.embedding for d in res.data]
        except (RateLimitError, APIError, APIConnectionError, Timeout) as e:
            wait = backoff ** attempt
            print(f"âš ï¸  Embed attempt {attempt}/{max_retry} failed: {e} â†’ retry in {wait}s")
            time.sleep(wait)
        except Exception as e:
            print(f"âŒ  Unexpected embed error: {e}")
            raise
    raise RuntimeError(f"Embedding failed after {max_retry} attempts")

 # â”€â”€ â¹ OpenAI ì„ë² ë”© (64ê°œì”© ë°°ì¹˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê°¯ìˆ˜ ìƒê´€ì—†ìŒ
BATCH = 64
embs = []
for i in range(0, len(docs), BATCH):
    embs.extend(embed(docs[i:i+BATCH]))
    print(f"  â†’ Embedded {len(embs)}/{len(docs)}")

# â”€â”€ â¹â€‘b ì˜ë¯¸Â·í˜•ì‹ ìµœëŒ€ ìœ ì‚¬ë„ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
max_sem_sims   = []
max_struct_sims = []

for i, emb_i in enumerate(embs):
    if i == 0:                    # ì²« í•­ëª©ì€ ìê¸° ìì‹ ë¿
        max_sem_sims.append(1.0)
        max_struct_sims.append(1.0)
        continue

    sem_scores   = [cosine_sim(emb_i, embs[j]) for j in range(i)]
    struct_scores = [pos_jaccard(pos_sets[i], pos_sets[j]) for j in range(i)]

    max_sem_sims.append(max(sem_scores))
    max_struct_sims.append(max(struct_scores))

# ë©”íƒ€ë°ì´í„°ì— ìœ ì‚¬ë„ ê¸°ë¡
for i, meta in enumerate(metas):
    meta["max_sem_sim"]   = round(max_sem_sims[i], 4)
    meta["max_struct_sim"] = round(max_struct_sims[i], 4)

# â”€â”€ âº Chroma ì»¬ë ‰ì…˜ì— ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
col.add(ids=ids, documents=docs, embeddings=embs, metadatas=metas)
print(f"âœ…  {len(ids)} items stored in {DB_PATH}:{COL_NAME}")