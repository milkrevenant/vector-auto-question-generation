import chromadb, re, os, json

from openai import OpenAI
import openai

openai.api_key = os.environ.get("OPENAI_API_KEY")

def generate_with_openai(new_passage, template_questions, n_questions=5):
    system = "You are a Korean CSAT question writer. Given example questions, create new ones for the new passage."
    user_prompt = f"""
ìƒˆ ì§€ë¬¸:
\"\"\"{new_passage}\"\"\"

ì˜ˆì‹œ ë¬¸ì œë“¤:
{chr(10).join(f"- {q}" for q in template_questions)}

ìœ„ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ ìƒˆë¡œìš´ ì§€ë¬¸ì— ë§ëŠ” ë¬¸ì œ {n_questions}ê°œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
"""
    resp = cli.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0.7,
        max_tokens=800,
    )
    text = resp.choices[0].message.content
    return [line.strip(" -") for line in text.splitlines() if line.strip()]


DB = "./sn_csat.db"; COL = "sn_csat_openai"
EMBED_MODEL = os.environ.get("OPENAI_EMBED_MODEL", "text-embedding-3-large")
TOP_K = 50                  # HNSW 1ì°¨ í›„ë³´ (ë” ë§ì€ í›„ë³´ ê²€ìƒ‰)
GROUP_PICK = 2              # ì§€ë¬¸ 2ê°œ ì„ íƒ


cli = OpenAI()
col = chromadb.PersistentClient(path=DB).get_collection(COL)

def embed(text):
    return cli.embeddings.create(model=EMBED_MODEL, input=text).data[0].embedding

def extract_group(doc_id: str):
    # ì˜ˆ: 23_11_37_2  â†’  23_11_37
    m = re.match(r"(\d{2}_\d{2}_\d{2})_", doc_id)
    return m.group(1) if m else doc_id

 # 0) ì§€ë¬¸ ìœ í˜• ì„ íƒ
categories = ["ë¬¸í•™", "ë…ì„œ", "í™”ë²•", "ì‘ë¬¸", "ì–¸ì–´", "ë§¤ì²´"]
print("ì§€ë¬¸ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:")
for idx, cat in enumerate(categories, 1):
    print(f"{idx}. {cat}")
sel = input("ë²ˆí˜¸ ë˜ëŠ” ìœ í˜•ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 1 ë˜ëŠ” ë¬¸í•™): ").strip()
if sel.isdigit() and 1 <= int(sel) <= len(categories):
    type_choice = categories[int(sel)-1]
elif sel in categories:
    type_choice = sel
else:
    type_choice = ""
    print("ì˜ëª»ëœ ì…ë ¥ì´ê±°ë‚˜ ì„ íƒë˜ì§€ ì•Šì•„ ì „ì²´ ìœ í˜•ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
print(f"ì„ íƒëœ ì§€ë¬¸ ìœ í˜•: {type_choice or 'ì „ì²´'}")

# 1) ìƒˆ ì§€ë¬¸ ì…ë ¥: íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ì§ì ‘ ì…ë ¥
input_choice = input("ğŸ“ ì§€ë¬¸ ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:\n1. íŒŒì¼ ê²½ë¡œ ì…ë ¥\n2. ì§ì ‘ í…ìŠ¤íŠ¸ ì…ë ¥\nì„ íƒ (1 ë˜ëŠ” 2): ").strip()

if input_choice == "1":
    file_path = input("ğŸ“ ì§€ë¬¸ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”:\n").strip()
    
    # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì²˜ë¦¬
    import subprocess
    import os
    
    if file_path.endswith('.rtf'):
        # RTF íŒŒì¼ ì²˜ë¦¬
        result = subprocess.run(['textutil', '-convert', 'txt', '-stdout', file_path], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            query = result.stdout
        else:
            print("RTF íŒŒì¼ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            raise Exception("RTF íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨")
    
    elif file_path.endswith('.docx'):
        # DOCX íŒŒì¼ ì²˜ë¦¬ (python-docx í•„ìš”)
        try:
            from docx import Document
            doc = Document(file_path)
            query = '\n'.join([para.text for para in doc.paragraphs if para.text])
        except ImportError:
            print("DOCX íŒŒì¼ì„ ì½ìœ¼ë ¤ë©´ python-docxë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install python-docx")
            raise
    
    elif file_path.endswith('.pdf'):
        # PDF íŒŒì¼ ì²˜ë¦¬ (pypdf í•„ìš”)
        try:
            import PyPDF2
            with open(file_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                query = ''
                for page in pdf_reader.pages:
                    query += page.extract_text()
        except ImportError:
            print("PDF íŒŒì¼ì„ ì½ìœ¼ë ¤ë©´ PyPDF2ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install PyPDF2")
            raise
    
    elif file_path.endswith(('.txt', '.md')):
        # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
        with open(file_path, encoding="utf-8") as f:
            query = f.read()
    
    else:
        # ê¸°íƒ€ íŒŒì¼ì€ í…ìŠ¤íŠ¸ë¡œ ì‹œë„
        try:
            with open(file_path, encoding="utf-8") as f:
                query = f.read()
        except UnicodeDecodeError:
            print(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {os.path.splitext(file_path)[1]}")
            raise

elif input_choice == "2":
    print("ğŸ“ ì§€ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì…ë ¥ ì™„ë£Œ í›„ ë¹ˆ ì¤„ì„ ë‘ ë²ˆ ì…ë ¥):")
    lines = []
    empty_count = 0
    while True:
        line = input()
        if line == "":
            empty_count += 1
            if empty_count >= 2:
                break
        else:
            empty_count = 0
            lines.append(line)
    query = '\n'.join(lines)

else:
    print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    exit()

print(f"\nì½ì–´ì˜¨ ì§€ë¬¸ (ì²˜ìŒ 200ì):\n{query[:200]}...")
q_vec = embed(query)

hits = col.query(query_embeddings=[q_vec], n_results=TOP_K)
ids    = hits["ids"][0]
metas  = hits["metadatas"][0]

# ë””ë²„ê¹…: ë©”íƒ€ë°ì´í„°ì—ì„œ ë…ì„œ ìœ í˜• í™•ì¸
doksu_count = sum(1 for meta in metas if meta.get("type") == "ë…ì„œ")
print(f"\në””ë²„ê¹…: ì „ì²´ {len(metas)}ê°œ í›„ë³´ ì¤‘ 'ë…ì„œ' ìœ í˜•: {doksu_count}ê°œ")

# 1) ìœ ì‚¬ ì§€ë¬¸ í›„ë³´ í‘œì‹œ ë° ê·¸ë£¹ ì„ íƒ (ì„ íƒëœ ìœ í˜• í•„í„°ë§)
distances = hits["distances"][0]
# í›„ë³´ ì¤‘ ì„ íƒëœ ìœ í˜•ë§Œ í•„í„°ë§
if type_choice:
    candidates = [(doc_id, meta, dist) for doc_id, meta, dist in zip(ids, metas, distances)
                  if meta.get("type") == type_choice]
    if not candidates:
        print(f"ì„ íƒëœ ìœ í˜• '{type_choice}'ì— í•´ë‹¹í•˜ëŠ” í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ í›„ë³´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        candidates = list(zip(ids, metas, distances))
else:
    candidates = list(zip(ids, metas, distances))
# ê±°ë¦¬ -> ìœ ì‚¬ë„ ë³€í™˜ ë° ì •ë ¬ (ë†’ì€ ìœ ì‚¬ë„ ìˆœ), ìƒìœ„ 8ê°œë§Œ
candidates_sim = [(doc_id, meta, dist, 1 - dist) for doc_id, meta, dist in candidates]
candidates_sorted = sorted(candidates_sim, key=lambda x: x[3], reverse=True)[:8]
print("\nâ–¶ ìœ ì‚¬ ì§€ë¬¸ í›„ë³´ (ìƒìœ„ 8ê°œ, ë†’ì€ ìœ ì‚¬ë„ ìˆœ):")
for idx, (_id, meta, dist, sim) in enumerate(candidates_sorted, 1):
    snippet = col.get(where={"id": _id})["documents"][0][:100].replace("\n", " ")
    print(f"{idx}. ID: {_id}, ìœ í˜•: {meta.get('type')}, ìœ ì‚¬ë„: {sim:.4f} (ê±°ë¦¬: {dist:.4f})")
    print(f"   ë¯¸ë¦¬ë³´ê¸°: {snippet}...")
selection = input("ì›í•˜ëŠ” ì§€ë¬¸ ë²ˆí˜¸ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 1,2):\n").strip()
chosen_idxs = [int(i) - 1 for i in selection.split(",") if i.strip().isdigit()]
uniq_groups = []
for i in chosen_idxs:
    _id = candidates_sorted[i][0]
    g = extract_group(_id)
    if g not in uniq_groups:
        uniq_groups.append(g)
print("\nì„ íƒëœ ì§€ë¬¸ ê·¸ë£¹:", uniq_groups)

# 2) ê° ê·¸ë£¹ì— ì†í•œ ëª¨ë“  ë¬¸ì œ ì„¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
all_sets = []
for g in uniq_groups:
    where_filter = {"group": g}
    group_docs = col.get(where=where_filter)
    for doc, meta in zip(group_docs["documents"], group_docs["metadatas"]):
        all_sets.append({"meta": meta, "doc": doc})

 # â€” ê²€ì¦ ë‹¨ê³„: ì¶”ì¶œëœ ì›ë³¸ ë¬¸ì œ ì„¸íŠ¸ í™•ì¸ â€”
old_questions = [s["meta"].get("question") for s in all_sets if s["meta"].get("question")]
print("\n>>> ì¶”ì¶œëœ ì›ë³¸ ë¬¸ì œ ì„¸íŠ¸:")
for idx, q in enumerate(old_questions, 1):
    print(f"{idx}. {q}")
input("\nìœ„ ë¬¸ì œ ì„¸íŠ¸ê°€ ë§ìœ¼ë©´ ì—”í„°ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”â€¦")

# 4) ìƒˆë¡œìš´ ë¬¸ì œ ìƒì„±
new_questions = generate_with_openai(query, old_questions, n_questions=5)
print("\nâ–¶ ìƒˆë¡­ê²Œ ìƒì„±ëœ ë¬¸ì œ:")
for idx, nq in enumerate(new_questions, 1):
    print(f"{idx}. {nq}")

# 3) ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
for i, s in enumerate(all_sets, 1):
    print(f"\n=== ì„¸íŠ¸ {i} / ê·¸ë£¹ {extract_group(s['meta']['id'])} ===")
    print(s["doc"][:800], "..." if len(s["doc"]) > 800 else "")
